---
title: "Propensity scores for continuous exposures"
format: html
---

```{r}
#| label: setup
library(tidyverse)
library(broom)
library(touringplans)
library(propensity)
```

For this set of exercises, we'll use propensity scores for continuous exposures.

In the touringplans data set, we have information about the posted waiting times for rides. We also have a limited amount of data on the observed, actual times. The question that we will consider is this: Do posted wait times (`wait_minutes_posted_avg`) for the Seven Dwarves Mine Train at 8 am affect actual wait times (`wait_minutes_actual_avg`) at 9 am? Here’s our DAG:

```{r}
#| echo: false
#| message: false
#| warning: false
library(ggdag)
library(ggokabeito)

coord_dag <- list(
  x = c(Season = -1, close = -1, weather = -2, extra = 0, x = 1, y = 2),
  y = c(Season = -1, close = 1, weather = 0, extra = 0, x = 0, y = 0)
)

labels <- c(
  extra = "Extra Magic Morning",
  x = "Average posted wait ",
  y = "Average acutal wait",
  Season = "Ticket Season",
  weather = "Historic high temperature",
  close = "Time park closed"
)

dagify(
  y ~ x + close + Season + weather + extra,
  x ~ weather + close + Season + extra,
  extra ~ weather + close + Season,
  coords = coord_dag,
  labels = labels,
  exposure = "x",
  outcome = "y"
) |>
  tidy_dagitty() |>
  node_status() |>
  ggplot(
    aes(x, y, xend = xend, yend = yend, color = status)
  ) +
  geom_dag_edges_arc(curvature = c(rep(0, 7), .2, 0, .2, .2, 0), edge_colour = "grey70") +
  geom_dag_point() +
  geom_dag_label_repel(
    aes(x, y, label = label),
    box.padding = 3.5, 
    inherit.aes = FALSE,
    max.overlaps = Inf, 
    family = "sans",
    seed = 1602,
    label.size = NA, 
    label.padding = 0.1,
    size = 14 / 3
  )  + 
  scale_color_okabe_ito(na.value = "grey90") +
  theme_dag() +
  theme(
    legend.position = "none",
    axis.text.x = element_text()
  ) +
  coord_cartesian(clip = "off") +
  scale_x_continuous(
    limits = c(-2.25, 2.25),
    breaks = c(-2, -1, 0, 1, 2),
    labels = c(
      "\n(one year ago)",
      "\n(6 months ago)",
      "\n(3 months ago)",
      "8am-9am\n(Today)",
      "9am-10am\n(Today)"
    )
  )
```

First, let’s wrangle our data to address our question: do posted wait times at 8 affect actual weight times at 9? We’ll join the baseline data (all covariates and posted wait time at 8) with the outcome (average actual time). We also have a lot of missingness for `wait_minutes_actual_avg`, so we’ll drop unobserved values for now.

You don't need to update any code here, so just run this.

```{r}
eight <- seven_dwarfs_train_2018 |>
  filter(wait_hour == 8) |>
  select(-wait_minutes_actual_avg)

nine <- seven_dwarfs_train_2018 |>
  filter(wait_hour == 9) |>
  select(park_date, wait_minutes_actual_avg)

wait_times <- eight |>
  left_join(nine, by = "park_date") |>
  drop_na(wait_minutes_actual_avg)
```

# Your Turn 1

First, let’s calculate the propensity score model, which will be the denominator in our stabilized weights (more to come on that soon). We’ll fit a model using `lm()` for `wait_minutes_posted_avg` with our covariates, then use the fitted predictions of `wait_minutes_posted_avg` (`.fitted`, `.sigma`) to calculate the density using `dnorm()`.

1. Fit a model using `lm()` with `wait_minutes_posted_avg` as the outcome and the confounders identified in the DAG.
2. Use `augment()` to add model predictions to the data frame.
3. In `wt_ate()`, calculate the weights using `wait_minutes_posted_avg`, `.fitted`, and `.sigma`.

```{r}
post_time_model <- lm(
  __________, 
  data = wait_times
)

wait_times_wts <- post_time_model |>
  ______(data = wait_times) |>
  mutate(wts = ______(
    ______, ______, .sigma = ______
  ))
```

# Your Turn 2

As with the example in the slides, we have a lot of extreme values for our weights

```{r}
wait_times_wts |>
  ggplot(aes(wts)) +
  geom_density(col = "#E69F00", fill = "#E69F0095") + 
  scale_x_log10() + 
  theme_minimal(base_size = 20) + 
  xlab("Weights")
```

Let’s now fit the marginal density to use for stabilized weights:

1. Re-fit the above using stabilized weights

```{r}
wait_times_swts <- post_time_model |>
  augment(data = wait_times) |>
    mutate(swts = _____(
    _____, 
    _____,
    .sigma = .sigma,
    _____ = _____
  ))
```

Take a look at the weights now that we've stabilized them:

```{r}
ggplot(wait_times_swts, aes(swts)) +
  geom_density(col = "#E69F00", fill = "#E69F0095") + 
  scale_x_log10() + 
  theme_minimal(base_size = 20) + 
  xlab("Stabilized Weights")
```

# Your Turn 3

Now, let's fit the outcome model!

1. Estimate the relationship between posted wait times and actual wait times using the stabilized weights we just created. 

```{r}
lm(___ ~ ___, weights = ___, data = wait_times_swts) |>
  tidy() |>
  filter(term == "wait_minutes_posted_avg") |>
  mutate(estimate = estimate * 10)
```

## Stretch goal: Boostrapped intervals

Bootstrap confidence intervals for our estimate.

There's nothing new here. Just remember, you need to bootstrap the entire modeling process!

```{r}
set.seed(1234)
library(rsample)

fit_model <- function(split, ...) { 
  .df <- analysis(split) 
  
  # fill in the rest!
}

model_estimate <- bootstraps(wait_times, 1000, apparent = TRUE) |>
  mutate(results = map(splits, ______))

# using bias-corrected confidence intervals
boot_estimate <- int_bca(_______, results, .fn = fit_model)

boot_estimate
```

***

# Take aways

* We can calculate propensity scores for continuous exposures. `wt_ate()` uses `dnorm()` to use the normal density to transform predictions to a propensity-like scale; we need to give `wt_ate()` `.sigma` as to calculate do this. We can also use other approaches like quantile binning of the exposure, calculating probability-based propensity scores using categorical regression models. 
* Continuous exposures are prone to mispecification and usually need to be stabilized. A simple stabilization is to invert the propensity score by stabilization weights using an intercept-only model such as `lm(exposure ~ 1)`. `wt_ate()` can do this for you automatically with `stabilize = TRUE`. This also applies to other types of exposures.
* Stabilization is useful for any type of exposure where the weights are unbounded. Weights like the ATO, making them less susceptible to extreme weights.
* Using propensity scores for continuous exposures in outcome models is identical to using them with binary exposures.
* Because propensity scores for continuous exposures are prone to positivity violation, check the bootstrap distribution of your estimate for skew and to see if the mean estimate is different from your regression model. If these problems are present, you may need to use another approach like g-computation.
