---
title: "Bonus: Selection bias and correcting for loss to follow-up"
format: html
---

```{r}
#| label: setup
library(tidyverse)
library(broom)
library(propensity)
library(causaldata)
library(rsample)
```

In this example, we'll consider loss to follow-up in the NHEFS study. We'll use the binary exposure we used earlier in the workshop: does quitting smoking (`smk`) increase weight (`wt82_71`)? This time, however, we'll adjust for loss to followup (people who dropped out of the study between observation periods) using inverse probability of censoring weights.

# Your Turn 1

1. Take a look at how many participants were lost to follow up in `nhefs`, called `censored` in this data set. You don't need to change anything in this code.

```{r}
nhefs_censored <- nhefs |>
  drop_na(
    qsmk, sex, race, age, school, smokeintensity, smokeyrs, exercise,
    active, wt71
  )

nhefs_censored |>
  count(censored = as.factor(censored)) |>
  ggplot(aes(censored, n)) + 
  geom_col()
```

2. Create a logistic regression model that predicts whether or not someone is censored. 

```{r}
cens_model <- ___(
  ______ ~ qsmk + sex + race + age + I(age^2) + education +
    smokeintensity + I(smokeintensity^2) +
    smokeyrs + I(smokeyrs^2) + exercise + active +
    wt71 + I(wt71^2),
  data = nhefs_censored, 
  family = binomial()
)
```

# Your Turn 2

1. Use the logistic model you just fit to create inverse probability of censoring weights
2. Calculate the weights using `.fitted`
3. Join `cens` to `nhefs_censored` so that you have the weights in your dataset
4. Fit a linear regression model of `wt82_71` weighted by `cens_wts`. We'll use this model as the basis for our G-computation

```{r}
cens <- _______ |>
  augment(type.predict = "response", data = nhefs_censored) |>
  mutate(cens_wts = wt_ate(censored, ______)) |>
  select(id, cens_wts)

#  join all the weights data from above
nhefs_censored_wts <- _______ |>
  left_join(_____, by = "id")

cens_model <- lm(
  ______ ~ qsmk + I(qsmk * smokeintensity) + smokeintensity +
    I(smokeintensity^2) + sex + race + age + I(age^2) + education + smokeyrs +
    I(smokeyrs^2) + exercise + active + wt71 + I(wt71^2),
  data = nhefs_censored_wts,
  weights = ______
)
```

# Your Turn 3

1. Create the cloned data sets, called `kept_smoking` and `no`, where one dataset has `quit_smoking` set to 1 (quit smoking) and the other has it set to 0 (kept smoking).
2. Use the outcome model, `cens_model`, to make predictions for `kept_smoking` and `quit_smoking` 
3. Calculate the differences between the mean values of `kept_smoking` and `quit_smoking`

```{r}
kept_smoking <- ____
quit_smoking <- ____

predicted_kept_smoking <- _______ |>
  augment(newdata = _______) |>
  select(kept_smoking = .fitted)

predicted_quit_smoking <- _______ |>
  augment(newdata = _______) |>
  select(quit_smoking = .fitted)

#  summarize the mean difference
bind_cols(predicted_kept_smoking, predicted_quit_smoking) |>
  summarise(
    
  )
```

## Stretch goal: Boostrapped intervals

Finish early? Try bootstrapping the G-computation model with censoring weights

Remember, you need to bootstrap the entire modeling process, including fitting both regression models, cloning the data sets, and calculating the effects.

```{r}
fit_gcomp_cens <- function(split, ...) { 
  .df <- analysis(split) 
  
  # fit the censoring model. remember to model using `.df` instead of `nhefs_censored`

    # calculate the inverse probability of censoring weights. remember to predict `.df` instead of `nhefs_censored`
  
  #  join all the weights data from above to .df
  
  # fit outcome model. remember to model using `nhefs_censored_wts` instead of `nhefs_censored` or `.df`
  
  # clone datasets. remember to clone `.df` instead of `nhefs_censored`
  
  # predict change in weight for each cloned dataset
  
  # calculate ATE
  bind_cols(predicted_kept_smoking, predicted_quit_smoking) |>
    summarize(
      mean_quit_smoking = mean(quit_smoking),
      mean_kept_smoking = mean(kept_smoking),
      difference = mean_quit_smoking - mean_kept_smoking
    ) |>
    # rsample expects a `term` and `estimate` column
    pivot_longer(everything(), names_to = "term", values_to = "estimate")
}

gcomp_cens_results <- bootstraps(nhefs_censored, 1000, apparent = TRUE) |>
  mutate(results = map(splits, ______))

# using bias-corrected confidence intervals
boot_estimate_cens <- int_bca(_______, results, .fn = fit_gcomp_cens)

boot_estimate_cens
```

***

# Take aways

* If loss to follow-up is potentially related to your study question, inverse probability of censoring weights can help mitigate the bias.
* You can use them in many types of models. If you're also using propensity score weights, simply multiply the weights together, then include the result as the weights for your outcome model.
