{
  "hash": "733a9389491dee38436fc0cbf34865a2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Continuous exposures with propensity scores\"\nauthor: \"Malcolm Barrett\"\ninstitute: \"Stanford University\"\nformat: \"kakashi-revealjs\"\n---\n\n\n\n## {background-color=\"#23373B\" .huge .center}\n### *Warning!* Propensity score weights are sensitive to positivity violations for continuous exposures. \n\n## {background-color=\"#23373B\" .huge .center}\n### **The story so far**\n\n---\n\n## Propensity score weighting {background-color=\"#23373B\"}\n\n1. Fit a propensity model predicting exposure `x`, `x + z` where z is all covariates\n2. Calculate weights \n3. Fit an outcome model estimating the effect of `x` on `y` weighted by the propensity score\n\n## Continous exposures {background-color=\"#23373B\"}\n\n1. Use a model like `lm(x ~ z)` for the propensity score model.\n2. Use `wt_ate()` with `.fitted` and `.sigma`; transforms using `dnorm()` to get on probability-like scale.\n3. Apply the weights to the outcome model as normal!\n\n## Alternative: quantile binning {background-color=\"#23373B\" .small} \n\n1. Bin the continuous exposure into quantiles and use categorical regression like a multinomial model to calculate probabilities.\n2. Calculate the weights where the propensity score is the probability you fall into the quantile you actually fell into. Same as the binary ATE!\n3. Same workflow for the outcome model\n\n## 1. Fit a model for `exposure ~ confounders`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel <- lm(\n  exposure ~ confounder_1 + confounder_2,\n  data = df\n)\n```\n:::\n\n\n## 2. Calculate the weights with `wt_ate()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|3-8\"}\nmodel |>\n  augment(data = df) |>\n  mutate(wts = wt_ate( \n    exposure, \n    .fitted, \n    # .sigma is from augment()\n    .sigma = .sigma\n  )) \n```\n:::\n\n\n## Does change in smoking intensity (`smkintensity82_71`) affect weight gain among lighter smokers?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnhefs_light_smokers <- nhefs_complete |>\n  filter(smokeintensity <= 25)\n```\n:::\n\n\n## 1. Fit a model for `exposure ~ confounders`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|1-2|3-6\"}\nnhefs_model <- lm(\n  smkintensity82_71 ~ sex + race + age + I(age^2) + \n    education + smokeintensity + I(smokeintensity^2) + \n    smokeyrs + I(smokeyrs^2) + exercise + active + \n    wt71 + I(wt71^2), \n  data = nhefs_light_smokers\n)\n```\n:::\n\n\n## 2. Calculate the weights with `wt_ate()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|3-7\"}\nnhefs_wts <- nhefs_model |> \n  augment(data = nhefs_light_smokers) |> \n  mutate(wts = wt_ate(\n    smkintensity82_71, \n    .fitted,\n    .sigma = .sigma\n  )) \n```\n:::\n\n\n\n## 2. Calculate the weights with `wt_ate()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnhefs_wts\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,162 × 74\n    seqn  qsmk death yrdth modth dadth   sbp   dbp sex  \n   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <fct>\n 1   235     0     0    NA    NA    NA   123    80 0    \n 2   244     0     0    NA    NA    NA   115    75 1    \n 3   245     0     1    85     2    14   148    78 0    \n 4   252     0     0    NA    NA    NA   118    77 0    \n 5   257     0     0    NA    NA    NA   141    83 1    \n 6   262     0     0    NA    NA    NA   132    69 1    \n 7   266     0     0    NA    NA    NA   100    53 1    \n 8   419     0     1    84    10    13   163    79 0    \n 9   420     0     1    86    10    17   184   106 0    \n10   434     0     0    NA    NA    NA   127    80 1    \n# ℹ 1,152 more rows\n# ℹ 65 more variables: age <dbl>, race <fct>, income <dbl>,\n#   marital <dbl>, school <dbl>, education <fct>, …\n```\n\n\n:::\n:::\n\n\n## Do *posted* wait times at 8 am affect *actual* wait times at 9 am?\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](14-bonus-continuous-pscores_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## *Your Turn 1*\n\n### Fit a model using `lm()` with `wait_minutes_posted_avg` as the outcome and the confounders identified in the DAG.\n### Use `augment()` to add model predictions to the data frame\n### In `wt_ate()`, calculate the weights using `wait_minutes_posted_avg`, `.fitted`, and `.sigma`\n\n`<div class=\"countdown\" id=\"timer_dd92e4a8\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">05</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>`{=html}\n\n## *Your Turn 1*\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npost_time_model <- lm(\n  wait_minutes_posted_avg ~\n    park_close + park_extra_magic_morning + \n    park_temperature_high + park_ticket_season, \n  data = wait_times\n)\n```\n:::\n\n\n## *Your Turn 1*\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwait_times_wts <- post_time_model |>\n  augment(data = wait_times) |>\n  mutate(wts = wt_ate(\n    wait_minutes_posted_avg, .fitted, .sigma = .sigma\n  ))\n```\n:::\n\n\n## *Stabilizing extreme weights*\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](14-bonus-continuous-pscores_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## Stabilizing extreme weights {background-color=\"#23373B\"}\n\n1. Fit an intercept-only model (e.g. `lm(x ~ 1)`) or use mean and SD of `x`\n2. Calculate weights from this model.\n3. Divide these weights by the propensity score weights. `wt_ate(.., stabilize = TRUE)` does this all!\n\n## Calculate stabilized weights \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|7\"}\nnhefs_swts <- nhefs_model |>\n  augment(data = nhefs_light_smokers) |>\n  mutate(swts = wt_ate(\n    smkintensity82_71, \n    .fitted, \n    .sigma = .sigma,\n    stabilize = TRUE\n  ))\n```\n:::\n\n\n## Stabilizing extreme weights\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](14-bonus-continuous-pscores_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='center' width=80%}\n:::\n:::\n\n\n## *Your Turn 2*\n\n### Re-fit the above using stabilized weights\n\n`<div class=\"countdown\" id=\"timer_2b762354\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>`{=html}\n\n## *Your Turn 2*\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwait_times_swts <- post_time_model |>\n  augment(data = wait_times) |>\n  mutate(swts = wt_ate(\n    wait_minutes_posted_avg, \n    .fitted,\n    .sigma = .sigma,\n    stabilize = TRUE\n  ))\n```\n:::\n\n\n## Fitting the outcome model {background-color=\"#23373B\"}\n\n1. Use the stabilized weights in the outcome model. Nothing new here!\n\n---\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|3,8\"}\nlm(\n  wt82_71 ~ smkintensity82_71, \n  weights = swts, \n  data = nhefs_swts\n) |>\n  tidy() |>\n  filter(term == \"smkintensity82_71\") |>\n  mutate(estimate = estimate * -10) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  term              estimate std.error statistic     p.value\n  <chr>                <dbl>     <dbl>     <dbl>       <dbl>\n1 smkintensity82_71     2.04    0.0335     -6.08     1.62e-9\n```\n\n\n:::\n:::\n\n\n## *Your Turn 3*\n\n### Estimate the relationship between posted wait times and actual wait times using the stabilized weights we just created. \n\n`<div class=\"countdown\" id=\"timer_a3ea2749\" data-update-every=\"1\" tabindex=\"0\" style=\"right:0;bottom:0;\">\n<div class=\"countdown-controls\"><button class=\"countdown-bump-down\">&minus;</button><button class=\"countdown-bump-up\">&plus;</button></div>\n<code class=\"countdown-time\"><span class=\"countdown-digits minutes\">03</span><span class=\"countdown-digits colon\">:</span><span class=\"countdown-digits seconds\">00</span></code>\n</div>`{=html}\n\n## *Your Turn 3*\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm(\n  wait_minutes_actual_avg ~ wait_minutes_posted_avg, \n  weights = swts, \n  data = wait_times_swts\n) |>\n  tidy() |>\n  filter(term == \"wait_minutes_posted_avg\") |>\n  mutate(estimate = estimate * 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 5\n  term                  estimate std.error statistic p.value\n  <chr>                    <dbl>     <dbl>     <dbl>   <dbl>\n1 wait_minutes_posted_…     2.40    0.0655      3.66 4.48e-4\n```\n\n\n:::\n:::\n\n\n\n## Diagnosing issues {background-color=\"#23373B\"}\n\n1. Extreme weights even after stabilization\n2. Bootstrap: non-normal distribution\n3. Bootstrap: estimate different from original model\n\n## More info {background-color=\"#23373B\"}\n\n### https://github.com/LucyMcGowan/writing-positivity-continous-ps\n",
    "supporting": [
      "14-bonus-continuous-pscores_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"14-bonus-continuous-pscores_files/libs/countdown-0.4.0/countdown.css\" rel=\"stylesheet\" />\n<script src=\"14-bonus-continuous-pscores_files/libs/countdown-0.4.0/countdown.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}